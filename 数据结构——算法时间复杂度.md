## 算法时间复杂度

#### 算法时间复杂度定义:
* 在进行算法分析时，语句总的**执行次数T(n)是关于问题规模n的函数**，进而分析T(n)随n的变化情况并确定T(n)的数量级。
* 算法的时间复杂度，也就是算法的时间量度，记作：T(n) = O(f(n))。
* 它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中**f(n)是问题规模n的某个函数**

用大写O()来提现算法时间复杂度的记法，我们称之为O记法。一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。
**一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。**

由此算法时间复杂度的定义可知，我们的三个求和算法的时间复杂度分别为O(n),O(1),O(n^2)

* O(1) 叫 常数阶
* O(n) 叫 线性阶
* O(n2)叫 平方阶


### 推导大O阶方法
1. **用常数1取代运行时间中的所有加法常数**0 
2. **在修改后的运行次数函数中，只保留最高阶级**
3. **如果最高阶项存在且不是1，则去除这个项相乘的常数**

得到的结果就是大O

常用的时间复杂度所耗费的时间从小到大依次是：
O(1)<O(logn)<O(n)<O(nlogn)<O(n^2)<O(n^3)<O(2^n)<O(n!)<O(n^n)